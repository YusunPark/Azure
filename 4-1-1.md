# Exercise 4_1_1 — Foundry 배포 모델을 LangChain으로 호출하기 (Windows/PowerShell)

## Step 0. 환경설정 (공통)
- Foundry에서 모델 배포
  - (허브가 없다면) 허브 생성 → 프로젝트 생성
  - 모델 카탈로그 → 채팅 모델 선택(`gpt5-chat`) → 배포 이름(예: `gpt5-chat`)
  - API 버전 호환 확인 → 배포 완료
  - 프로젝트 엔드포인트 확인: `https://<your-resource>.openai.azure.com/`
    - 이 값은 `AZURE_OPENAI_ENDPOINT`에 사용합니다.

- 로컬 가상환경 + 패키지 설치
  - 경로에 `[]`가 있으면 `Activate.ps1`이 실패할 수 있어 venv의 `python.exe`를 직접 호출합니다.
```pwsh
py -3 -m venv .venv
".\.venv\Scripts\python.exe" -m pip install -U pip
".\.venv\Scripts\python.exe" -m pip install "langchain>=0.3" "langchain-openai>=0.2" python-dotenv
```

- 환경 변수 설정(.env 권장 또는 PowerShell 임시 설정)
  - .env 예시
```dotenv
AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/
AZURE_OPENAI_API_KEY=<your-key>
AZURE_OPENAI_API_VERSION=<api-version>
AZURE_OPENAI_DEPLOYMENT=gpt5-chat
```
  - PowerShell 임시 설정
```pwsh
$env:AZURE_OPENAI_ENDPOINT="https://<your-resource>.openai.azure.com/"
$env:AZURE_OPENAI_API_KEY="<your-key>"
$env:AZURE_OPENAI_API_VERSION="<api-version>"
$env:AZURE_OPENAI_DEPLOYMENT="gpt5-chat"
```

## Step A. app_basic.py — 단일 질문/응답

### 코드 추가(Code — 단계별, 아래 순서대로 같은 파일에 이어서 붙여넣으세요)

#### 1) 파일 생성과 임포트
```python
# file: app_basic.py
import os
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
```
> 설명: 이 예제는 LangChain과 AzureChatOpenAI를 사용합니다. 한 파일(`app_basic.py`)에 누적 작성합니다.

#### 2) 환경 변수 읽기(Foundry 배포/키/엔드포인트)
```python
# Azure OpenAI 설정
endpoint = os.environ["AZURE_OPENAI_ENDPOINT"]
api_key = os.environ["AZURE_OPENAI_API_KEY"]
api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-21")

# 배포 이름: Foundry에서 만든 배포명과 동일해야 함
DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt5-chat")
```
> 설명: 환경 변수는 Step 0에서 설정했습니다. 배포명이 다르면 404가 납니다.

#### 3) LLM 인스턴스 생성
```python
llm = AzureChatOpenAI(
		azure_endpoint=endpoint,
		api_key=api_key,
		api_version=api_version,
		azure_deployment=DEPLOYMENT_NAME,
		temperature=0.4,
		max_retries=3,
		timeout=30,
)
```
> 설명: `temperature`는 창의성, `max_retries`/`timeout`은 안정성(재시도/타임아웃) 설정입니다.

#### 4) 프롬프트와 체인 정의
```python
prompt = ChatPromptTemplate.from_messages([
	("system", "너는 바쁜 사람들을 돕는 초간결 비서야. 핵심만 3~5문장으로, 가벼운 유머는 한 번만."),
	("user", "{question}"),
])

chain = prompt | llm | StrOutputParser()
```
> 설명: 시스템 메시지로 톤을 고정하고, `StrOutputParser`로 문자열만 뽑습니다.

#### 5) 실행부(main)
```python
if __name__ == "__main__":
	answer = chain.invoke({
		"question": "헬스장 초보를 위한 1주일 운동 루틴을 제안해줘. 주의사항 포함!"
	})
	print("\n[답변]\n" + answer)
```
> 설명: 한 번 질문하고 한 번 답을 받는 최소 실행 예입니다.

### 실행(Run)
```pwsh
python app_basic.py
```

## Step B. app_stream.py — 스트리밍 출력

#### 1) 파일 생성과 임포트
```python
# file: app_stream.py
import os, sys
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
```
> 설명: 스트리밍 출력 표시를 위해 `sys.stdout`을 사용합니다.

#### 2) 환경 변수 읽기
```python
endpoint = os.environ["AZURE_OPENAI_ENDPOINT"]
api_key = os.environ["AZURE_OPENAI_API_KEY"]
api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-21")
DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt5-chat")
```

#### 3) LLM 인스턴스 생성
```python
llm = AzureChatOpenAI(
		azure_endpoint=endpoint,
		api_key=api_key,
		api_version=api_version,
		azure_deployment=DEPLOYMENT_NAME,
		temperature=0.5,
)
```
> 설명: 스트리밍은 모델 설정과 별개로 `chain.stream()` 호출 시 활성화됩니다.

#### 4) 프롬프트/체인 정의
```python
prompt = ChatPromptTemplate.from_messages([
	("system", "너는 실전형 요약 비서야. 답변은 번호 매긴 3~5단계로, 각 단계는 한 문장. 실행 가능한 동사로 시작하고 과장된 표현은 피해."),
	("user", "{question}"),
])
chain = prompt | llm | StrOutputParser()

if __name__ == "__main__":
	for chunk in chain.stream({
		"question": "퇴근 후 30분 안에 만들 수 있는 건강한 저녁 메뉴 3가지를 추천해줘. 대략적인 재료비도 알려줘."
	}):
		sys.stdout.write(chunk)
		sys.stdout.flush()
	print()
```

> 설명: `chain.stream()`은 토큰 단위로 부분 결과를 내보내며, UI에서 실시간 표시 UX를 구현할 때 유용합니다.

### 실행(Run)
```pwsh
python app_stream.py
```

## Step C. app_rag_like_skeleton.py — 후처리 체인

#### 1) 파일 생성과 임포트
```python
# file: app_rag_like_skeleton.py
# 실제 RAG는 아님. LangChain의 조합(LCEL)로 후처리를 보여주는 예시

import os, sys
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
```
> 설명: LCEL 조합으로 “생성 → 후처리” 2단계 체인을 구성합니다.

#### 2) 환경 변수 읽기
```python
endpoint = os.environ["AZURE_OPENAI_ENDPOINT"]
api_key = os.environ["AZURE_OPENAI_API_KEY"]
api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-21")
DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt5-chat")
```

#### 3) LLM 인스턴스 생성
```python
llm = AzureChatOpenAI(
		azure_endpoint=endpoint,
		api_key=api_key,
		api_version=api_version,
		azure_deployment=DEPLOYMENT_NAME,
)
```

#### 4) 1단계: 원문을 만드는 프롬프트
```python
prompt = ChatPromptTemplate.from_messages([
	("system", "너는 실용적인 조언가야. 모르면 '모른다'고 말해. 핵심만 불릿 5개 이내로."),
	("user", "{question}"),
])
```

#### 5) 2단계: 슬라이드용 후처리 프롬프트 템플릿
```python
post_format = ChatPromptTemplate.from_template(
	"""
다음 답변을 발표 슬라이드용으로 다듬어줘.
- 불릿 5개 이하
- 각 불릿은 12단어 이하 한국어 문장
- 지나친 전문 용어는 줄이고 명확한 표현 사용
원문:
```{raw}```
	"""
)
```

#### 6) 체인 구성(원문 체인 → 폴리싱 체인)
```python
parse = StrOutputParser()
chain = prompt | llm | parse
polish_chain = ({"raw": chain}) | post_format | llm | parse
```

#### 7) 실행부(스트리밍)
```python
if __name__ == "__main__":
	for chunk in polish_chain.stream({
		"question": "신규 팀원이 2주 안에 온보딩하도록 핵심 활동 계획 5가지를 제안해줘. 각 활동 이유는 간단히."
	}):
		sys.stdout.write(chunk)
		sys.stdout.flush()
```
> 설명: 1단계 생성 결과를 `raw`로 넘겨 2단계에서 슬라이드용 텍스트로 다듬습니다.

### 실행(Run)
```pwsh
python app_rag_like_skeleton.py
```


5) Azure Portal UI에서 Agent를 만들기
- 파일을 올려보기
- 플레이 그라운드에서 테스트
- 코드 옮겨보기
- 테스트 후 실행

## Step D. Azure Foudry Agent Service에서 Agent 만들기 & 실습 가이드

### 1. 에이전트 생성 단계
- Azure AI Foundry에서 gpt-4o 모델을 `gpt-4o`라는 이름으로 배포합니다.
- 포털 경로 예: Azure AI Foundry 프로젝트 → Build → Agents (또는 Assistants) → Create
- 필드 작성 예시
	- Name: `lecture-advisor`
	- System instructions (예시):"당신은 사내 지식 파일을 기반으로 실용적인 답변을 제공하는 어시스턴트입니다. 모호한 질문이면 명확화 질문을 먼저 던지고, 사실이 없는 내용은 추측하지 마세요. 답변은 5문장 이하로." 
- Model / Deployment: `gpt-4o` (이미 생성한 배포 선택)
저장(Create) 후 Agent ID 또는 Resource/Deployment 이름을 기록합니다.

### 2. 파일 업로드 및 플레이그라운드에서 테스트
Agent 상세 화면 → Files / 지식 → 추가
- [강의 안내 사이트](https://adorable-hail-415.notion.site/KT-ds-MS-AI-1f9137efedf68028aec6c315379e637e?p=226137efedf680b4abd9de56031e2eef&pm=s)에서 pdf 문서 다운로드
- `KT _오픈소스 & MS AI_ 강의 커리큘럼.pdf` 파일 업로드
- 플레이 그라운드로 이동
- "4일차 강의 커리큘럼이 뭐야"와 같은 질문 후 문서를 바탕으로 질의 응답을 하는 지 확인

### 3. 코드 보기로 코드 복사해서 실행
- 파이썬 파일을 만들어 `코드 보기`에서 코드를 복사한 후 붙여넣습니다.
- `message`의 `Content`의 내용을 `오늘 4일차 강의가 뭐야?`로 바꿔서 코드를 실행합니다.